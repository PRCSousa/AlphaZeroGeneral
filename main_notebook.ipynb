{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Zero For Generalized Game Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação do jogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que vamos implementar, nuances, etc,etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Go():\n",
    "\n",
    "    EMPTY = 0\n",
    "    BLACK = 1\n",
    "    WHITE = -1\n",
    "    BLACKMARKER = 4\n",
    "    WHITEMARKER = 5\n",
    "    LIBERTY = 8\n",
    "\n",
    "    def __init__(self):\n",
    "        self.row_count = 9\n",
    "        self.column_count = 9\n",
    "        self.komi = 6.5\n",
    "        self.action_size = self.row_count * self.column_count + 1\n",
    "        self.liberties = []\n",
    "        self.block = []\n",
    "        self.seki_liberties = []\n",
    "        \n",
    "    def get_initial_state(self):\n",
    "        board = np.zeros((self.row_count, self.column_count))\n",
    "        return board\n",
    "    \n",
    "\n",
    "    def count(self, x, y, state: list, player:int , liberties: list, block: list) -> tuple[list, list]:\n",
    "        '''\n",
    "        # Description:\n",
    "        Counts the number of liberties of a stone and the number of stones in a block.\n",
    "        Follows a recursive approach to count the liberties of a stone and the number of stones in a block.\n",
    "\n",
    "        # Returns:\n",
    "        A tuple containing the number of liberties and the number of stones in a block.\n",
    "        '''\n",
    "        \n",
    "        #initialize piece\n",
    "        piece = state[y][x]\n",
    "        #if there's a stone at square of the given player\n",
    "        if piece == player:\n",
    "            #save stone coords\n",
    "            block.append((y,x))\n",
    "            #mark the stone\n",
    "            if player == self.BLACK:\n",
    "                state[y][x] = self.BLACKMARKER\n",
    "            else:\n",
    "                state[y][x] = self.WHITEMARKER\n",
    "            \n",
    "            #look for neighbours recursively\n",
    "            if y-1 >= 0:\n",
    "                liberties, block = self.count(x,y-1,state,player,liberties, block) #walk north\n",
    "            if x+1 < self.column_count:\n",
    "                liberties, block = self.count(x+1,y,state,player,liberties, block) #walk east\n",
    "            if y+1 < self.row_count:\n",
    "                liberties, block = self.count(x,y+1,state,player,liberties, block) #walk south\n",
    "            if x-1 >= 0:\n",
    "                liberties, block = self.count(x-1,y,state,player,liberties, block) #walk west\n",
    "\n",
    "        #if square is empty\n",
    "        elif piece == self.EMPTY:\n",
    "            #mark liberty\n",
    "            state[y][x] = self.LIBERTY\n",
    "            #save liberties\n",
    "            liberties.append((y,x))\n",
    "\n",
    "        # print(\"Liberties: \" + str(len(self.liberties)) + \" in: \" + str(x) + \",\" + str(y))\n",
    "        # print(\"Block: \" + str(len(self.block)) + \" in: \" + str(x) + \",\" + str(y))\n",
    "        return liberties, block\n",
    "\n",
    "    #remove captured stones\n",
    "    def clear_block(self, block: list, state: list) -> list:\n",
    "        '''\n",
    "        # Description:\n",
    "        Clears the block of stones captured by the opponent on the board.\n",
    "\n",
    "        # Returns:\n",
    "        The board with the captured stones removed.\n",
    "        '''\n",
    "\n",
    "        #clears the elements in the block of elements which is captured\n",
    "        for i in range(len(block)): \n",
    "            y, x = block[i]\n",
    "            state[y][x] = self.EMPTY\n",
    "        \n",
    "        return state\n",
    "\n",
    "    #restore board after counting stones and liberties\n",
    "    def restore_board(self, state: list) -> list:\n",
    "        '''\n",
    "        # Description:\n",
    "        Restores the board to its original state after counting liberties and stones.\n",
    "        This is done by unmarking the stones following bitwise operations with the global class variables.\n",
    "        \n",
    "        # Returns:\n",
    "        The board with the stones unmarked.\n",
    "        '''\n",
    "\n",
    "        #unmark stones\n",
    "        # print(\"Restore Board\")\n",
    "        # print(state)\n",
    "        for y in range(len(state)):\n",
    "            for x in range(len(state)):\n",
    "                #restore piece\n",
    "                val = state[y][x]\n",
    "                if val == self.BLACKMARKER:\n",
    "                    state[y][x] = self.BLACK\n",
    "                elif val == self.WHITEMARKER:\n",
    "                    state[y][x] = self.WHITE\n",
    "                elif val == self.LIBERTY:\n",
    "                    state[y][x] = self.EMPTY\n",
    "\n",
    "        # print(\"After Restore Board\")\n",
    "        # print(state)\n",
    "        return state\n",
    "\n",
    "    def print_board(self, state: list) -> None:\n",
    "            '''\n",
    "            # Description:\n",
    "            Draws the board in the console.\n",
    "\n",
    "            # Returns:\n",
    "            None\n",
    "            '''\n",
    "\n",
    "        # Print column coordinates\n",
    "            print(\"   \", end=\"\")\n",
    "            for j in range(len(state[0])):\n",
    "                print(f\"{j:2}\", end=\" \")\n",
    "            print(\"\\n  +\", end=\"\")\n",
    "            for _ in range(len(state[0])):\n",
    "                print(\"---\", end=\"\")\n",
    "            print()\n",
    "\n",
    "            # Print rows with row coordinates\n",
    "            for i in range(len(state)):\n",
    "                print(f\"{i:2}|\", end=\" \")\n",
    "                for j in range(len(state[0])):\n",
    "                    print(f\"{str(int(state[i][j])):2}\", end=\" \")\n",
    "                print()\n",
    "    \n",
    "    def captures(self, state: list,player: int, a:int, b:int) -> tuple[bool, list]:\n",
    "        '''\n",
    "        # Description:\n",
    "        Checks if a move causes a capture of stones of the player passed as an argument.\n",
    "        If a move causes a capture, the stones are removed from the board.\n",
    "\n",
    "        # Returns:\n",
    "        A tuple containing a boolean indicating if a capture has been made and the board with the captured stones removed.\n",
    "        '''\n",
    "        check = False\n",
    "        neighbours = []\n",
    "        if(a > 0): neighbours.append((a-1, b))\n",
    "        if(a < self.column_count - 1): neighbours.append((a+1, b))\n",
    "        if(b > 0): neighbours.append((a, b - 1))\n",
    "        if(b < self.row_count - 1): neighbours.append((a, b+1))\n",
    "\n",
    "        #loop over the board squares\n",
    "        for pos in neighbours:\n",
    "            # print(pos)\n",
    "            x = pos[0]\n",
    "            y = pos[1]    \n",
    "            # init piece\n",
    "            piece = state[x][y]\n",
    "\n",
    "                #if stone belongs to given colour\n",
    "            if piece == player:\n",
    "                # print(\"opponent piece\")\n",
    "                # count liberties\n",
    "                liberties = []\n",
    "                block = []\n",
    "                liberties, block = self.count(y, x, state, player, liberties, block)\n",
    "                # print(\"Liberties in count: \" + str(len(liberties)))\n",
    "                # if no liberties remove the stones\n",
    "                if len(liberties) == 0: \n",
    "                    #clear block\n",
    "                    state = self.clear_block(block, state)\n",
    "                    check = True\n",
    "\n",
    "                #restore the board\n",
    "                state = self.restore_board(state)\n",
    "\n",
    "        #print(\"Captures: \" + str(check))\n",
    "        return check, state\n",
    "    \n",
    "    def set_stone(self, a, b, state, player):\n",
    "        state[a][b] = player\n",
    "        return state\n",
    "    \n",
    "    def get_next_state(self, state, action, player):\n",
    "        '''\n",
    "        # Description\n",
    "        Plays the move, verifies and undergoes captures and saves the state to the history.\n",
    "        \n",
    "        # Returns:\n",
    "        New state with everything updated.\n",
    "        '''\n",
    "        if action == self.row_count * self.column_count:\n",
    "            return state # pass move\n",
    "\n",
    "        a = action // self.row_count\n",
    "        b = action % self.column_count\n",
    "\n",
    "        # checking if the move is part of is the secondary move to a ko fight\n",
    "        state = self.set_stone(a, b, state, player)\n",
    "        # print(state)\n",
    "        state = self.captures(state, -player, a, b)[1]\n",
    "        return state\n",
    "    \n",
    "    def is_valid_move(self, state: list, action: tuple, player: int) -> bool:\n",
    "        '''\n",
    "        # Description:\n",
    "        Checks if a move is valid.\n",
    "        If a move repeats a previous state or commits suicide (gets captured without capturing back), it is not valid.\n",
    "        \n",
    "        A print will follow explaining the invalid move in case it exists.\n",
    "\n",
    "        # Returns:\n",
    "        A boolean confirming the validity of the move.\n",
    "        '''\n",
    "\n",
    "        a = action[0]\n",
    "        b = action[1]\n",
    "\n",
    "        #print(f\"{a} , {b}\")\n",
    "\n",
    "        statecopy = np.copy(state).astype(np.int8)\n",
    "\n",
    "        if state[a][b] != self.EMPTY:\n",
    "            # print(\"Space Occupied\")\n",
    "            return False \n",
    "\n",
    "\n",
    "        statecopy = self.set_stone(a,b,statecopy,player)\n",
    "\n",
    "        if self.captures(statecopy, -player, a, b)[0] == True:\n",
    "            return True\n",
    "        else:\n",
    "            #print(\"no captures\")\n",
    "            libs, block = self.count(b,a,statecopy,player,[],[])\n",
    "            #print(libs)\n",
    "            if len(libs) == 0:\n",
    "                #print(\"Invalid, Suicide\")\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        \n",
    "\n",
    "    def get_valid_moves(self, state, player):\n",
    "        '''\n",
    "        # Description:\n",
    "        Returns a matrix with the valid moves for the current player.\n",
    "        '''\n",
    "        newstate = np.zeros((self.row_count, self.column_count))\n",
    "        for a in range(0, self.column_count):\n",
    "            for b in range(0, self.row_count):\n",
    "                if self.is_valid_move(state, (a,b), player):\n",
    "                    newstate[a][b] = 1\n",
    "        \n",
    "        newstate = newstate.reshape(-1)\n",
    "        newstate = np.concatenate([newstate, [1]])\n",
    "        return (newstate).astype(np.int8)\n",
    "\n",
    "    def get_value_and_terminated(self, state, action, player):\n",
    "        '''\n",
    "        # Description:\n",
    "        Returns the value of the state and if the game is over.\n",
    "        '''\n",
    "\n",
    "        scoring, endgame = self.scoring(state)\n",
    "\n",
    "        if endgame:\n",
    "            if player == self.BLACK:\n",
    "                if scoring > 0:\n",
    "                    return 1, True\n",
    "                else:\n",
    "                    return -1, True\n",
    "            else:\n",
    "                if scoring < 0:\n",
    "                    return 1, True\n",
    "                else:\n",
    "                    return -1, True\n",
    "        else:\n",
    "            if player == self.BLACK:\n",
    "                if scoring > 0:\n",
    "                    return 1, False\n",
    "                else:\n",
    "                    return -1, False\n",
    "            else:\n",
    "                if scoring < 0:\n",
    "                    return 1, False\n",
    "                else:\n",
    "                    return -1, False\n",
    "\n",
    "\n",
    "        \n",
    "    def scoring(self, state):\n",
    "        '''\n",
    "        # Description:\n",
    "        Checks the score of the game.\n",
    "        '''\n",
    "        black = 0\n",
    "        white = 0\n",
    "        empty = 0\n",
    "        endgame = True\n",
    "        # print(\"Scoring\")\n",
    "        for x in range(self.column_count):\n",
    "            for y in range(self.row_count):\n",
    "                if state[x][y] == self.EMPTY:\n",
    "                    empty += 1\n",
    "                    if empty >= self.column_count * self.row_count // 5: # if more than 1/4 of the board is empty, it is not the endgame\n",
    "                        endgame = False\n",
    "\n",
    "        black, white = self.count_influenced_territory_enhanced(state)\n",
    "                            \n",
    "        return black - (white + self.komi), endgame\n",
    "    \n",
    "    def count_influenced_territory_enhanced(self, board):\n",
    "        black_territory = 0\n",
    "        white_territory = 0\n",
    "        visited = set()\n",
    "\n",
    "        # Function to calculate influence score\n",
    "        def influence_score(x, y):\n",
    "            score = 0\n",
    "            for dx, dy in [(1, 0), (-1, 0), (0, 1), (0, -1)]:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if 0 <= nx < len(board) and 0 <= ny < len(board[0]):\n",
    "                    score += board[nx][ny]\n",
    "            return score\n",
    "\n",
    "        # Function to explore territory\n",
    "        def explore_territory(x, y):\n",
    "            nonlocal black_territory, white_territory\n",
    "            if (x, y) in visited or not (0 <= x < len(board) and 0 <= y < len(board[0])):\n",
    "                return\n",
    "            visited.add((x, y))\n",
    "\n",
    "            if board[x][y] == 0:\n",
    "                score = influence_score(x, y)\n",
    "                if score > 0:\n",
    "                    black_territory += 1\n",
    "                elif score < 0:\n",
    "                    white_territory += 1\n",
    "\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[0])):\n",
    "                if board[i][j] == 0 and (i, j) not in visited:\n",
    "                    explore_territory(i, j)\n",
    "\n",
    "        return black_territory, white_territory\n",
    "\n",
    "\n",
    "    def get_opponent(self, player):\n",
    "        return -player\n",
    "    \n",
    "    def get_opponent_value(self, value):\n",
    "        return -value\n",
    "    \n",
    "    def get_encoded_state(self, state):\n",
    "        layer_1 = np.where(np.array(state) == -1, 1, 0).astype(np.float32)\n",
    "        layer_2 = np.where(np.array(state) == 0, 1, 0).astype(np.float32)\n",
    "        layer_3 = np.where(np.array(state) == 1, 1, 0).astype(np.float32)\n",
    "\n",
    "        result = np.stack([layer_1, layer_2, layer_3]).astype(np.float32)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def change_perspective(self, state, player):\n",
    "        return state * player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Interface Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "data={'player1':(201,153,255),\n",
    "      'player2':(179,236,255),\n",
    "      }\n",
    "\n",
    "SIZE_BOARD = 9\n",
    "BLACK = (0,0,0)\n",
    "WHITE = (255,255,255)\n",
    "GREEN = (140, 217, 166)\n",
    "\n",
    "\n",
    "pygame.init()\n",
    "pygame_icon = pygame.image.load('image.png')\n",
    "pygame.display.set_icon(pygame_icon)\n",
    "\n",
    "SCREEN_SIZE=600\n",
    "SCREEN_PADDING = 50\n",
    "CELL_SIZE = (SCREEN_SIZE - SCREEN_PADDING) // SIZE_BOARD\n",
    "PIECE_SIZE = (SCREEN_SIZE - 2*SCREEN_PADDING) // SIZE_BOARD // 3\n",
    "\n",
    "screen=pygame.display.set_mode((SCREEN_SIZE,SCREEN_SIZE))\n",
    "\n",
    "pygame.display.set_caption(\"gO depression\")\n",
    "\n",
    "def to_pixels(x):\n",
    "    return SCREEN_PADDING + x*CELL_SIZE\n",
    "\n",
    "def to_coord(x):\n",
    "    quarter = CELL_SIZE//4\n",
    "    closest = (x-SCREEN_PADDING)//CELL_SIZE\n",
    "    if abs(to_pixels(closest)-(x-SCREEN_PADDING > to_pixels(closest)-(x-SCREEN_PADDING+quarter))):\n",
    "        closest = (x-SCREEN_PADDING+quarter)//CELL_SIZE\n",
    "    return closest\n",
    "\n",
    "def draw_board():\n",
    "    pygame.draw.rect(screen, GREEN, rect=(SCREEN_PADDING, SCREEN_PADDING, CELL_SIZE*(SIZE_BOARD-1), CELL_SIZE*(SIZE_BOARD-1)))\n",
    "    for i in range(SIZE_BOARD):\n",
    "        pygame.draw.line(screen, BLACK,(to_pixels(i),SCREEN_PADDING),(to_pixels(i),CELL_SIZE*(SIZE_BOARD-1) + SCREEN_PADDING),3)\n",
    "        pygame.draw.line(screen, BLACK,(SCREEN_PADDING,to_pixels(i)),(CELL_SIZE*(SIZE_BOARD-1)+SCREEN_PADDING,to_pixels(i)),3)\n",
    "\n",
    "def draw_piece(x,y,player):\n",
    "    color = BLACK if player == -1 else WHITE\n",
    "    pygame.draw.circle(screen,color,(to_pixels(x),to_pixels(y)),PIECE_SIZE)\n",
    "    pygame.draw.circle(screen,BLACK,(to_pixels(x),to_pixels(y)),PIECE_SIZE,3)\n",
    "\n",
    "def hover_to_select(player,valid_moves,click):\n",
    "    mouse_x, mouse_y = pygame.mouse.get_pos()\n",
    "    x, y = None, None\n",
    "    if ([to_coord(mouse_x), to_coord(mouse_y)] in valid_moves):\n",
    "        x, y = to_coord(mouse_x), to_coord(mouse_y)\n",
    "    \n",
    "    if (x!=None):\n",
    "        pixels = (to_pixels(x),to_pixels(y))\n",
    "        distance = pygame.math.Vector2(pixels[0] - mouse_x, pixels[1] - mouse_y).length()\n",
    "        if distance < PIECE_SIZE:\n",
    "            s = pygame.Surface((SCREEN_SIZE, SCREEN_SIZE), pygame.SRCALPHA)\n",
    "            if player == 1:\n",
    "                pygame.draw.circle(s,(255,255,255,200),(to_pixels(x),to_pixels(y)),PIECE_SIZE)\n",
    "            if player == -1:\n",
    "                pygame.draw.circle(s,(0,0,0,200),(to_pixels(x),to_pixels(y)),PIECE_SIZE)\n",
    "            pygame.draw.circle(s,BLACK,(to_pixels(x),to_pixels(y)),PIECE_SIZE,3)\n",
    "            screen.blit(s, (0, 0))\n",
    "        if click:\n",
    "            cur_pieces.append([x, y, player])\n",
    "            valid_moves.remove([x, y])\n",
    "            return [x, y, -1*player]\n",
    "    return [None, None, player]\n",
    "\n",
    "click = False\n",
    "valid_moves = []\n",
    "for i in range(SIZE_BOARD):\n",
    "    for j in range(SIZE_BOARD):\n",
    "        valid_moves.append([i, j])\n",
    "\n",
    "cur_pieces = []\n",
    "player = 1\n",
    "\n",
    "while True:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "        if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            click = True\n",
    "        if event.type == pygame.MOUSEBUTTONUP:\n",
    "            click = False\n",
    "\n",
    "    screen.fill(GREEN)\n",
    "    draw_board()\n",
    "\n",
    "    for piece in cur_pieces:\n",
    "        draw_piece(piece[0], piece[1], piece[2])\n",
    "\n",
    "    x, y, player = hover_to_select(player, valid_moves, click)\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Interface Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaZero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "SAVE_NAME = None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    GAME = input(\"Game: (Go/Attaxx) \")\n",
    "\n",
    "    LOAD = input(\"Load:\\nTrue will load a previous model, False will start from scratch (True/False):\\n\")\n",
    "    if LOAD == 'True':\n",
    "        LOAD = True\n",
    "        SAVE_NAME = input(\"Alias of the model: \")\n",
    "        MODEL = input(\"Model name: \")\n",
    "        OPT = input(\"Optimizer name: \")\n",
    "    else:\n",
    "        LOAD = False\n",
    "        SAVE_NAME = input(\"Alias of the new model: \")\n",
    "\n",
    "    TEST = input(\"Test:\\nTrue will play against the model, False will train the model (True/False):\\n\")\n",
    "    if TEST == 'True':\n",
    "        TEST = True\t\n",
    "    else:\n",
    "        TEST = False\n",
    "\n",
    "    if GAME == 'Go':\n",
    "        args = {\n",
    "            'game': 'Go',\n",
    "            'num_iterations': 20,             # number of highest level iterations\n",
    "            'num_selfPlay_iterations': 20,   # number of self-play games to play within each iteration\n",
    "            'num_mcts_searches': 500,         # number of mcts simulations when selecting a move within self-play\n",
    "            'max_moves': 512,                 # maximum number of moves in a game (to avoid infinite games which should not happen but just in case)\n",
    "            'num_epochs': 1200,                  # number of epochs for training on self-play data for each iteration\n",
    "            'batch_size': 128,                # batch size for training\n",
    "            'temperature': 1.30,              # temperature for the softmax selection of moves\n",
    "            'C': 2,                           # the value of the constant policy\n",
    "            'augment': True,                 # whether to augment the training data with flipped states\n",
    "            'dirichlet_alpha': 0.03,           # the value of the dirichlet noise (alpha)\n",
    "            'dirichlet_epsilon': 0.25,        # the value of the dirichlet noise (epsilon)\n",
    "            'alias': ('Go' + SAVE_NAME)\n",
    "        }\n",
    "\n",
    "        game = Go()\n",
    "        model = ResNet(game, 9, 3, device)\n",
    "        optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "    elif GAME == 'Attaxx':\n",
    "        game_size = [5,5]\n",
    "        args = {\n",
    "            'game': 'Attaxx',\n",
    "            'num_iterations': 10,              # number of highest level iterations\n",
    "            'num_selfPlay_iterations': 1000,   # number of self-play games to play within each iteration\n",
    "            'num_mcts_searches': 500,         # number of mcts simulations when selecting a move within self-play\n",
    "            'max_moves': 512,                 # maximum number of moves in a game (to avoid infinite games which should not happen but just in case)\n",
    "            'num_epochs': 500,                  # number of epochs for training on self-play data for each iteration\n",
    "            'batch_size': 500,                # batch size for training\n",
    "            'temperature': 1.25,              # temperature for the softmax selection of moves\n",
    "            'C': 2,                           # the value of the constant policy\n",
    "            'augment': False,                 # whether to augment the training data with flipped states\n",
    "            'dirichlet_alpha': 0.3,           # the value of the dirichlet noise\n",
    "            'dirichlet_epsilon': 0.125,       # the value of the dirichlet noise\n",
    "            'alias': ('Attaxx' + SAVE_NAME)\n",
    "        }\n",
    "\n",
    "        game = Attaxx(game_size)\n",
    "        model = ResNet(game, 20, 48, device)\n",
    "        optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "    if LOAD:\n",
    "        model.load_state_dict(torch.load(f'AlphaZero/Models/{GAME+SAVE_NAME}/{MODEL}.pt', map_location=device))\n",
    "        #model.load_state_dict(torch.load(f'AlphaZero/Models/{GAME+SAVE_NAME}/{MODEL}.pt', map_location=torch.device('cpu')))\n",
    "        optimizer.load_state_dict(torch.load(f'AlphaZero/Models/{GAME+SAVE_NAME}/{OPT}.pt', map_location=device))\n",
    "\n",
    "    if not TEST:\n",
    "        os.makedirs(f'AlphaZero/Models/{GAME+SAVE_NAME}', exist_ok=True)\n",
    "        alphaZero = AlphaZero(model, optimizer, game, args)\n",
    "        alphaZero.learn()\n",
    "    else:\n",
    "        if not LOAD:\n",
    "            print(\"No model to test\")\n",
    "            exit()\n",
    "        if GAME == 'Go':\n",
    "            game = Go()\n",
    "\n",
    "            model.load_state_dict(torch.load(f'AlphaZero/Models/{GAME+SAVE_NAME}/{MODEL}.pt'))\n",
    "            mcts = MCTS(model, game, args)\n",
    "            state = game.get_initial_state()\n",
    "            game.print_board(state)\n",
    "\n",
    "            player = 1\n",
    "\n",
    "            while True:\n",
    "                if player == 1:\n",
    "                    a, b = tuple(int(x.strip()) for x in input(\"\\nInput your move: \").split(' '))\n",
    "                    print(\"\\n\")\n",
    "                    action = a * 9 + b\n",
    "                    state = game.get_next_state(state, action, player)\n",
    "                else:\n",
    "                    neut = game.change_perspective(state, player)\n",
    "                    action = mcts.search(neut, player)\n",
    "                    action = np.argmax(action)\n",
    "                    print(f\"\\nAlphaZero Action: {action // game.row_count} {action % game.column_count}\\n\")\n",
    "                    state = game.get_next_state(state, action, player)\n",
    "\n",
    "                winner, win = game.get_value_and_terminated(state, action, player)\n",
    "                if win:\n",
    "                    game.print_board(state)\n",
    "                    print(f\"player {winner} wins\")\n",
    "                    exit()\n",
    "\n",
    "                player = - player\n",
    "                game.print_board(state)\n",
    "            \n",
    "        elif GAME == 'Attaxx':\n",
    "            game = Attaxx([5,5])\n",
    "\n",
    "            model.load_state_dict(torch.load(f'AlphaZero/Models/{GAME+SAVE_NAME}/{MODEL}.pt', map_location=device))\n",
    "            mcts = MCTS(model, game, args)\n",
    "            state = game.get_initial_state()\n",
    "            game.print_board(state)\n",
    "\n",
    "            player = 1\n",
    "\n",
    "            while True:\n",
    "                if player == 1:\n",
    "                    move = tuple(int(x.strip()) for x in input(\"\\nInput your move: \").split(' '))\n",
    "                    print(\"\\n\")\n",
    "                    action = game.move_to_int(move)\n",
    "                    state = game.get_next_state(state, action, player)\n",
    "                else:\n",
    "                    #neut = game.change_perspective(state, player)\n",
    "                    #print(neut)\n",
    "                    action = mcts.search(state, player)\n",
    "                    action = np.argmax(action)\n",
    "                    print(f\"\\nAlphaZero Action: {game.int_to_move(action)}\\n\")\n",
    "                    state = game.get_next_state(state, action, player)\n",
    "\n",
    "                winner, win = game.get_value_and_terminated(state, action, player)\n",
    "                if win:\n",
    "                    game.print_board(state)\n",
    "                    print(f\"player {winner} wins\")\n",
    "                    exit()\n",
    "\n",
    "                player = -player\n",
    "                game.print_board(state)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
